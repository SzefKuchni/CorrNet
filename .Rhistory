grep('#bacardi', text)
text[10]
text[103]
nchar(text[103])
grep('#bacardi', text)
nchar(text[grep('#bacardi', text)])
text[[103]]
gregexpr("bacardi", text[[103]])
grep("bacardi", text[[103]])
gregexpr("bacardi", text[[103]])
gregexpr("bacardi", text[[103]])[[1]]
substring(x[[103]],
gregexpr("bacardi", text[[103]])[[1]]-20,
gregexpr("bacardi", text[[103]])[[1]]+20)
gregexpr("bacardi", text[[103]])[[1]]
unname(gregexpr("bacardi", text[[103]])[[1]])
gregexpr("bacardi", text[[103]])[[1]][1]
devel(gregexpr("bacardi", text[[103]]))
??devel
attr(gregexpr("bacardi", text[[103]]))
attributes(gregexpr("bacardi", text[[103]]))
gregexpr("bacardi", text[[103]])
gregexpr("bacardi", text[[103]], useBytes = FALSE)
gregexpr("bacardi", text[[103]], useBytes = TRUE)
attributes("bacardi", text[[103]])
attributes(gregexpr("bacardi", text[[103]]))
position<-gregexpr("bacardi", text[[103]]))
position<-gregexpr("bacardi", text[[103]])
attributes(position)
numeric(position)
as.numeric(position)
unlist(position)
position<-unlist(gregexpr("bacardi", text[[103]]))
position<-unlist(gregexpr("bacardi", text[[103]]))
substring(x[[103]],
gregexpr("bacardi", position-20,
gregexpr("bacardi", position+20)
)
substring(x[[103]], position-20, position+20)
substring(x[[103]], position-20, position+20)
substring(text[[103]], position-20, position+20)
substring(text[[103]], position-20, position+50)
substring(text[[103]], position-50, position)
substring(text[[103]], position-50, position+50)
position<-unlist(gregexpr("caption", text[[103]]))
position
substring(text[[103]], position-50, position+50)
substring(text[[103]], position, position+100)
position_start<-unlist(gregexpr("caption", text[[103]]))
position_stop<-unlist(gregexpr("comments", text[[103]]))
substring(text[[103]], position_start, position_stop)
position_start<-unlist(gregexpr("caption", text[[103]]))
position_stop<-unlist(gregexpr("comments", text[[103]]))
substring(text[[103]], position_start, position_stop)
position_start
position_stop
substring(text[[103]], position-50, position+50)
position<-unlist(gregexpr("comments", text[[103]]))
substring(text[[103]], position-50, position+50)
position<-unlist(gregexpr("comments\", text[[103]]))
substring(text[[103]], position-50, position+50)
position_start<-unlist(gregexpr("caption", text[[103]]))
position_stop<-unlist(gregexpr("comments", text[[103]]))
substring(text[[103]], position_start, position_stop)
position<-unlist(gregexpr("comments", text[[103]]))
substring(text[[103]], position-50, position+50)
position<-unlist(gregexpr("caption", text[[103]]))
substring(text[[103]], position-50, position+50)
substring(text[[103]], position-50, position+500)[1]
gregexpr("caption.*(comments)\\", text[[103]])
gregexpr("caption.*(comments)//", text[[103]])
gregexpr("caption.*(comments)/", text[[103]])
gregexpr("caption.*(comments)\\", text[[103]])
gregexpr("caption.*(comments)\\\"", text[[103]])
gregexpr("caption.*(comments)\\", text[[103]])
gregexpr("caption.*(comments)\\/g", text[[103]])
gregexpr("caption.*comments", text[[103]])
gregexpr("bacardi", text[[103]])
gregexpr("caption", text[[103]])
gregexpr("caption.*(comments)\_", text[[103]])
gregexpr("caption.*(comments)[^_]", text[[103]])
regexpr("caption.*(comments)[^_]", text[[103]])
position<-unlist(gregexpr("caption", text[[103]]))
substring(text[[103]], position-50, position+500)[1]
substring(text[[103]], position-50, position+500)[1:3]
gregexpr("bacardi", text[[103]])
gregexpr("caption.*(comments)[^_]", text[[103]])
gregexpr("bacardi", text[[103]])
position<-unlist(gregexpr("caption", text[[103]]))
substring(text[[103]], position-50, position+50)
substring(text[[103]], position, position+100)
gregexpr("caption.*(comments)[^_]", text[[103]])
text[[103]]
gregexpr("bacardi", text[[103]])
gregexpr("caption.*comments[^_]", text[[103]])
gregexpr("caption.*comments[^_]", text[[103]], perl = TRUE)
gregexpr("caption.*comments[^_]", text[[103]], perl = FALSE)
position_start<-unlist(gregexpr("caption", text[[103]]))
position_stop<-unlist(gregexpr("comments[^_]", text[[103]]))
position_start
position_stop
substring(text[[103]], position_start, position_stop)
substring(text[[103]], position_start, position_stop+7)
test<-strsplit(text[[103]], " ")
test
test<-strsplit(text[[103]], "code")
test
text = readLines('bacardi.html')
text
grep('#bacardi', text)
nchar(text[grep('#bacardi', text)])
text[[103]]
position_start<-unlist(gregexpr("caption", text[[103]]))
position_stop<-unlist(gregexpr("comments[^_]", text[[103]]))
substring(text[[103]], position_start, position_stop+7)
gregexpr("caption.*comments[^_]", text[[103]])
gregexpr("caption", text[[103]])
gregexpr("comments", text[[103]])
gregexpr("comments[^_]", text[[103]])
gregexpr("caption.*comments[^_]", text[[103]])
gregexpr("caption", text[[103]])
gregexpr("comments[^_]", text[[103]])
gregexpr("(caption.*comments[^_])*", text[[103]])
gregexpr("caption.*comments[^_]", text[[103]])
gregexpr("caption.?comments[^_]", text[[103]])
gregexpr("caption.+?comments[^_]", text[[103]])
test<-gregexpr("caption.+?comments[^_]", text[[103]])
test[[1]][1]
attr(test, 'match.length')
attributes(test)
class(test)
test[[1]]$match.length
attributes(test[[1]])
attr(test[[1]],'match.lengtj')
attr(test[[1]],'match.length')
test<-gregexpr("caption.+?comments[^_]", text[[103]])
comment_length<-attr(test[[1]],'match.length')
test
unlist(test)
position<-unlist(test)
comment_length<-attr(test[[1]],'match.length')
position
comment_length
gregexpr("bacardi", text[[103]])
gregexpr("bacardi", text[[103]])
text[[103]]
comments<-gregexpr("caption.+?comments[^_]", text[[103]])
comments_length<-attr(comments[[1]],'match.length')
comments_position<-unlist(comments)
comments_flag<-gregexpr("caption.+?comments[^_]", text[[103]])
source('~/.active-rstudio-document', echo=TRUE)
#download local copy of web page
download.file(url = 'https://www.instagram.com/explore/tags/bacardi/', 'bacardi.html')
#read this into R
text = readLines('bacardi.html')
#serach for mension of bacardi (hashtag)
grep('#bacardi', text)
#number of letter
nchar(text[grep('#bacardi', text)])
#photos are in 103
gregexpr("bacardi", text[[103]])
#####################Extracting comments
#caption.+?comments[^_]
comments_flag<-gregexpr("caption.+?comments[^_]", text[[103]])
comments_position<-unlist(comments_flag)
comments_length<-attr(comments_flag[[1]],'match.length')
comments_flag<-substring(text[[103]], comments_position, comments_position+comments_length)
comments_flag<-gregexpr("caption.+?comments[^_]", text[[103]])
comments_length<-attr(comments_flag[[1]],'match.length')
comments_position<-unlist(comments_flag)
comments<-substring(text[[103]], comments_position, comments_position+comments_length)
comments
cat(comments)
print(comments)
comments[1]
comments[2]
grep(pattern = "Casamusica",comments)
commentsgrep(pattern = "Casamusica",comments)
comments[grep(pattern = "Casamusica",comments)]
[grep(pattern = "Casamusica",comments)]
grep(pattern = "Casamusica",comments)
comments
file('bacardi.txt')
conn<-file('bacardi.txt')
writeLines(text, conn)
#download local copy of web page
download.file(url = 'https://www.instagram.com/explore/tags/bacardi/', 'bacardi.html')
#read this into R
text = readLines('bacardi.html')
grep('media', text)
gregexpr("media", text[[103]])
text[[103]]
gregexpr("media", text[[103]])
text[[103]][304:]
nchar(text[[103]])
text[[103]][304:nchar(text[[103]])]
substr(text[[103]],304)
substr(text[[103]],304,nchar(text[[103]]))
substr(text[[103]],300,nchar(text[[103]]))
substr(text[[103]],303,nchar(text[[103]]))
substr(text[[103]],302,nchar(text[[103]]))
test<-substr(text[[103]],302,nchar(text[[103]]))
strsplit(test,"}, {")
strsplit(test,"\}, \{")
strsplit(test,"\\}, \\{")
test
trimws(strsplit(test,"\\}, \\{"))
test2<-trimws(strsplit(test,"\\}, \\{"))
strsplit(test,"\\}, \\{")
test2<-gsub(pattern = " ", replacement = "", x = strsplit(test,"\\}, \\{"))
test2
test2<-strsplit(test,"\\}, \\{")
test<-substr(text[[103]],302,nchar(text[[103]]))
test
test2<-strsplit(test[1],"\\}, \\{")
test2<-strsplit(test,"\\}, \\{")
test2[[1]]
trimws(test2[[1]])
test2<-gsub(pattern = " ", replacement = "", x = test2[[1]])
test2
test2<-gsub(pattern = "\n", replacement = "", x = test2[[1]])
test2
test<-substr(text[[103]],302,nchar(text[[103]]))
test2<-strsplit(test,"\\}, \\{")
test2
test3<-gsub(pattern = "\n", replacement = "", x = test2)
test3
test3<-gsub(pattern = "\n", replacement = "", x = test2[[1]])
test3
test3<-gsub(pattern = "\t", replacement = "", x = test2[[1]])
test3
test3<-gsub(pattern = " ", replacement = "", x = test2[[1]])
test3
test2
conn<-file('bacardi.txt')
writeLines(test2, conn)
test3<-test2[[1]]
conn<-file('bacardi.txt')
writeLines(test3, conn)
parse(test3)
htmlParse(test3)
xmlParse(test3)
test3
grep('display_src', test3)
gregexpr('display_src', test3)
unlist(gregexpr('display_src', test3))
test3
unlist(gregexpr('caption', test3))
start<-unlist(gregexpr('display_src', test3))
stop<-unlist(gregexpr('caption', test3))
urls<-substring(test3, start, stop)
urls
test3
start<-unlist(gregexpr('display_src', test3))
start
gregexpr('display_src', test3)
test3[15]
test
test2<-strsplit(test,"top_posts")
test2
test2[[1]][1]
test2[[1]][2]
getwd()
Setwd("desktop.ini")
setwd("C:/Users/T540pDLEWYNBQ/Desktop/Bacardi")
setwd("C:/Users/T540pDLEWYNBQ/Desktop/Bacardi")
list.files()
list.files("scrapped_data/")
files<-list.files("scrapped_data/")
files
files<-list.files("scrapped_data/")
length(files)
print(i)
for(i in 1:length(files)){
print(i)
}
for(i in 1:length(files)){
print(paste("scrapped_data/",files[i],sep = ""))
#temp<-read.csv(file = paste("scrapped_data/",files[i],sep = ""))
}
extraction_date<-substr(files[i],17,27)
extraction_date
extraction_date<-substr(files[i],17,26)
extraction_date
extraction_time<-substr(files[i],28,36)
extraction_time
extraction_time<-substr(files[i],28,35)
extraction_time
data<-data.frame(temp,extraction_date, extraction_time)
temp<-read.csv(file = paste("scrapped_data/",files[i],sep = ""))
data<-data.frame(temp,extraction_date, extraction_time)
View(data)
test<-read.csv("scrapped_data/hashtag_bacardi_2017-07-11_15-10-03.csv")
View(test)
test<-read.csv("scrapped_data/hashtag_bacardi_2017-07-11_15-40-08.csv")
View(test)
test$data[5]
stage4<-data.frame(test$data)
View(stage4)
final<-stage4 %>%
mutate("caption"=str_extract(pattern = "caption.+?comments[^_]", data),
"caption2"=substr(caption, 12, nchar(caption)-13),
"id"=str_extract(pattern = "id.+?dimensions", data),
"id2"=substr(id, 7, nchar(id)-14),
"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
"owner2"=substr(owner, 17, nchar(owner)-18),
"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
"image2"=substr(image, 18, nchar(image)-23),
"likes"=str_extract(pattern = "likes.+?\\}", data),
"likes2"=substr(likes, 18, nchar(likes)-1),
"comments"=str_extract(pattern = "comments[^_].+?likes", data),
"comments2"=substr(comments, 22, nchar(comments)-9),
"hashtag"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
library(dplyr)
final<-stage4 %>%
mutate("caption"=str_extract(pattern = "caption.+?comments[^_]", data),
"caption2"=substr(caption, 12, nchar(caption)-13),
"id"=str_extract(pattern = "id.+?dimensions", data),
"id2"=substr(id, 7, nchar(id)-14),
"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
"owner2"=substr(owner, 17, nchar(owner)-18),
"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
"image2"=substr(image, 18, nchar(image)-23),
"likes"=str_extract(pattern = "likes.+?\\}", data),
"likes2"=substr(likes, 18, nchar(likes)-1),
"comments"=str_extract(pattern = "comments[^_].+?likes", data),
"comments2"=substr(comments, 22, nchar(comments)-9),
"hashtag"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
library(stringr)
final<-stage4 %>%
mutate("caption"=str_extract(pattern = "caption.+?comments[^_]", data),
"caption2"=substr(caption, 12, nchar(caption)-13),
"id"=str_extract(pattern = "id.+?dimensions", data),
"id2"=substr(id, 7, nchar(id)-14),
"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
"owner2"=substr(owner, 17, nchar(owner)-18),
"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
"image2"=substr(image, 18, nchar(image)-23),
"likes"=str_extract(pattern = "likes.+?\\}", data),
"likes2"=substr(likes, 18, nchar(likes)-1),
"comments"=str_extract(pattern = "comments[^_].+?likes", data),
"comments2"=substr(comments, 22, nchar(comments)-9),
"hashtag"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
final<-stage4 %>%
mutate("caption"=str_extract(pattern = "caption.+?comments[^_]", data),
"caption2"=substr(caption, 12, nchar(caption)-13),
"id"=str_extract(pattern = "id.+?dimensions", data),
"id2"=substr(id, 7, nchar(id)-14),
"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
"owner2"=substr(owner, 17, nchar(owner)-18),
"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
"image2"=substr(image, 18, nchar(image)-23),
"likes"=str_extract(pattern = "likes.+?\\}", data),
"likes2"=substr(likes, 18, nchar(likes)-1),
"comments"=str_extract(pattern = "comments[^_].+?likes", data),
"comments2"=substr(comments, 22, nchar(comments)-9),
#"hashtag"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
stage4
View(stage4)
stage4<-data.frame("data"=test$data)
final<-stage4 %>%
mutate("caption"=str_extract(pattern = "caption.+?comments[^_]", data),
"caption2"=substr(caption, 12, nchar(caption)-13),
"id"=str_extract(pattern = "id.+?dimensions", data),
"id2"=substr(id, 7, nchar(id)-14),
"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
"owner2"=substr(owner, 17, nchar(owner)-18),
"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
"image2"=substr(image, 18, nchar(image)-23),
"likes"=str_extract(pattern = "likes.+?\\}", data),
"likes2"=substr(likes, 18, nchar(likes)-1),
"comments"=str_extract(pattern = "comments[^_].+?likes", data),
"comments2"=substr(comments, 22, nchar(comments)-9),
"hashtag"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
View(final)
final<-stage4 %>%
mutate("caption"=str_extract(pattern = "caption.+?comments[^_]", data),
"caption2"=substr(caption, 12, nchar(caption)-13),
"id"=str_extract(pattern = "id.+?dimensions", data),
"id2"=substr(id, 7, nchar(id)-14),
"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
"owner2"=substr(owner, 17, nchar(owner)-18),
"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
"image2"=substr(image, 18, nchar(image)-23),
"likes"=str_extract(pattern = "likes.+?\\}", data),
"likes2"=substr(likes, 18, nchar(likes)-1),
"comments"=str_extract(pattern = "comments[^_].+?likes", data),
"comments2"=substr(comments, 22, nchar(comments)-9),
"hashtag"=str_extract_all(data, pattern = "#[A-Za-z]+"),
"hashtag2"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
"hashtag"=str_extract_all(data, pattern = "#[A-Za-z]+"),
"hashtag2"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
final<-stage4 %>%
mutate(#"caption"=str_extract(pattern = "caption.+?comments[^_]", data),
#"caption2"=substr(caption, 12, nchar(caption)-13),
#"id"=str_extract(pattern = "id.+?dimensions", data),
#"id2"=substr(id, 7, nchar(id)-14),
#"owner"=str_extract(pattern = "owner.+?thumbnail_src", data),
#"owner2"=substr(owner, 17, nchar(owner)-18),
#"image"=str_extract(pattern = "thumbnail_src.+?thumbnail_resources", data),
#"image2"=substr(image, 18, nchar(image)-23),
#"likes"=str_extract(pattern = "likes.+?\\}", data),
#"likes2"=substr(likes, 18, nchar(likes)-1),
#"comments"=str_extract(pattern = "comments[^_].+?likes", data),
#"comments2"=substr(comments, 22, nchar(comments)-9),
"hashtag"=str_extract_all(data, pattern = "#[A-Za-z]+"),
"hashtag2"=lapply(str_extract_all(data, pattern = "#[A-Za-z]+"),paste, collapse=" "),
"date"=str_extract(pattern = "date.+?display_src", data),
"date2"=substr(date, 8, nchar(date)-14))
stage4$data[5]
stage4$data[5]
stage4$data[5]
text_LR = readLines('C:/Users/T540pDLEWYNBQ/Google Drive/Wszystko/Inne/Studia doktoranckie - Informatyka/CorrNet/CorrNet/test_LR.txt')
text_LR
grep('view1 to view2', text_LR)
idx<-grep('view1 to view2', text_LR)
text_LR[idx+1]
view1_to_view2<-as.numeric(text_LR[idx+1])
view1_to_view2
idx<-grep('view2 to view1', text_LR)
idx
view2_to_view1<-as.numeric(text_LR[idx+1])
view2_to_view1
text_LR
idx<-grep('validation correlation', text_LR)
validation_correlation<-as.numeric(text_LR[idx+1])
validation_correlation
idx<-grep('test correlation', text_LR)
test_correlation<-as.numeric(text_LR[idx+1])
test_correlation
result<-data.frame("Type"="LR",
"view1_to_view2"=view1_to_view2,
"view2_to_view1"=view2_to_view1,
"validation_correlation"=validation_correlation,
"test_correlation"=test_correlation)
result
#read this into R
text_UD = readLines('C:/Users/T540pDLEWYNBQ/Google Drive/Wszystko/Inne/Studia doktoranckie - Informatyka/CorrNet/CorrNet/test_UD.txt')
#serach for view1 to view2
idx<-grep('view1 to view2', text_UD)
view1_to_view2<-as.numeric(text_UD[idx+1])
#serach for view2 to view1
idx<-grep('view2 to view1', text_UD)
view2_to_view1<-as.numeric(text_UD[idx+1])
#serach for validation correlation
idx<-grep('validation correlation', text_UD)
validation_correlation<-as.numeric(text_UD[idx+1])
#serach for test correlation
idx<-grep('test correlation', text_UD)
test_correlation<-as.numeric(text_UD[idx+1])
result<-data.frame("Type"="UD",
"view1_to_view2"=view1_to_view2,
"view2_to_view1"=view2_to_view1,
"validation_correlation"=validation_correlation,
"test_correlation"=test_correlation)
result
result<-rbind(result_LR,result_UD)
#read this into R
text_LR = readLines('C:/Users/T540pDLEWYNBQ/Google Drive/Wszystko/Inne/Studia doktoranckie - Informatyka/CorrNet/CorrNet/test_LR.txt')
#serach for view1 to view2
idx<-grep('view1 to view2', text_LR)
view1_to_view2<-as.numeric(text_LR[idx+1])
#serach for view2 to view1
idx<-grep('view2 to view1', text_LR)
view2_to_view1<-as.numeric(text_LR[idx+1])
#serach for validation correlation
idx<-grep('validation correlation', text_LR)
validation_correlation<-as.numeric(text_LR[idx+1])
#serach for test correlation
idx<-grep('test correlation', text_LR)
test_correlation<-as.numeric(text_LR[idx+1])
result_LR<-data.frame("Type"="LR",
"view1_to_view2"=view1_to_view2,
"view2_to_view1"=view2_to_view1,
"validation_correlation"=validation_correlation,
"test_correlation"=test_correlation)
#read this into R
text_UD = readLines('C:/Users/T540pDLEWYNBQ/Google Drive/Wszystko/Inne/Studia doktoranckie - Informatyka/CorrNet/CorrNet/test_UD.txt')
#serach for view1 to view2
idx<-grep('view1 to view2', text_UD)
view1_to_view2<-as.numeric(text_UD[idx+1])
#serach for view2 to view1
idx<-grep('view2 to view1', text_UD)
view2_to_view1<-as.numeric(text_UD[idx+1])
#serach for validation correlation
idx<-grep('validation correlation', text_UD)
validation_correlation<-as.numeric(text_UD[idx+1])
#serach for test correlation
idx<-grep('test correlation', text_UD)
test_correlation<-as.numeric(text_UD[idx+1])
result_UD<-data.frame("Type"="UD",
"view1_to_view2"=view1_to_view2,
"view2_to_view1"=view2_to_view1,
"validation_correlation"=validation_correlation,
"test_correlation"=test_correlation)
result<-rbind(result_LR,result_UD)
result
setwd("C:/Users/T540pDLEWYNBQ/Google Drive/Wszystko/Inne/Studia doktoranckie - Informatyka/CorrNet/CorrNet")
write.csv("experiment_results.csv", row.names = F)
write.csv(result, "experiment_results.csv", row.names = F)
